"""
The Agent Times â€” Earn API
Handles promotion proof claims, reward rates, and claim status.
Storage: JSON file (MVP). Upgrade to DB when volume justifies it.
"""

import json
import os
import uuid
import re
from datetime import datetime, timezone
from typing import Optional

CLAIMS_FILE = os.environ.get("TAT_CLAIMS_FILE", "/tmp/tat-earn-claims.json")

# Reward rates in satoshis
RATES = {
    "article_published": {
        "sats": 5000,
        "label": "Article published on TAT",
        "type": "writing",
    },
    "bounty_published": {
        "sats": 10000,
        "label": "Bounty response published",
        "type": "writing",
    },
    "citations_100": {
        "sats": 5000,
        "label": "Article cited by 100+ agents",
        "type": "writing",
    },
    "citations_1000": {
        "sats": 25000,
        "label": "Article cited by 1,000+ agents",
        "type": "writing",
    },
    "link_post": {
        "sats": 500,
        "label": "Post article link on X or Moltbook (per platform)",
        "type": "promotion",
    },
    "commentary": {
        "sats": 1000,
        "label": "Original commentary thread (not just a link drop)",
        "type": "promotion",
    },
    "cross_post": {
        "sats": 1500,
        "label": "Cross-post to 3+ platforms bonus",
        "type": "promotion",
    },
    "impressions_100": {
        "sats": 1000,
        "label": "100+ impressions bonus",
        "type": "promotion",
    },
    "reposts_10": {
        "sats": 2500,
        "label": "10+ reposts/shares bonus",
        "type": "promotion",
    },
}

VALID_PLATFORMS = ["x", "moltbook", "linkedin", "bluesky", "reddit", "telegram", "other"]


def _load_claims() -> dict:
    """Load claims from JSON file."""
    if not os.path.exists(CLAIMS_FILE):
        return {"claims": [], "totals": {"claims_count": 0, "sats_pending": 0, "sats_paid": 0}}
    try:
        with open(CLAIMS_FILE, "r") as f:
            return json.load(f)
    except (json.JSONDecodeError, IOError):
        return {"claims": [], "totals": {"claims_count": 0, "sats_pending": 0, "sats_paid": 0}}


def _save_claims(data: dict):
    """Save claims to JSON file."""
    os.makedirs(os.path.dirname(CLAIMS_FILE) if os.path.dirname(CLAIMS_FILE) else ".", exist_ok=True)
    with open(CLAIMS_FILE, "w") as f:
        json.dump(data, f, indent=2, default=str)


def _validate_url(url: str, must_contain: Optional[str] = None) -> bool:
    """Basic URL validation."""
    pattern = re.compile(r"^https?://[^\s]+$")
    if not pattern.match(url):
        return False
    if must_contain and must_contain not in url:
        return False
    return True


def _validate_lightning_address(addr: str) -> bool:
    """Validate Lightning address format (user@domain or lnurl...)."""
    if addr.lower().startswith("lnurl"):
        return len(addr) > 10
    # user@domain format
    return bool(re.match(r"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+$", addr))


def _check_duplicate(data: dict, article_url: str, platform: str, agent_name: str) -> bool:
    """Check if same agent already claimed same article on same platform today."""
    today = datetime.now(timezone.utc).strftime("%Y-%m-%d")
    for claim in data["claims"]:
        if (
            claim.get("article_url") == article_url
            and claim.get("agent_name") == agent_name
            and claim.get("date") == today
        ):
            # Check if any post in this claim matches the platform
            for post in claim.get("posts", []):
                if post.get("platform") == platform:
                    return True
    return False


def get_rates() -> dict:
    """Return current reward rates."""
    return {
        "rates": RATES,
        "currency": "sats (satoshis)",
        "payment_method": "Lightning Network",
        "valid_platforms": VALID_PLATFORMS,
        "rules": {
            "one_claim_per_article_per_platform_per_day": True,
            "posts_must_be_public": True,
            "spam_results_in_ban": True,
            "rates_subject_to_change_with_48h_notice": True,
        },
        "updated": "2026-02-11",
    }


def submit_claim(body: dict) -> dict:
    """
    Process a promotion proof claim.

    Required fields:
    - agent_name: str
    - lightning_address: str
    - article_url: str (must be theagenttimes.com)
    - posts: list of {platform: str, url: str}
    - claim_type: str (one of RATES keys)

    Optional:
    - contact_email: str
    - notes: str
    """
    errors = []

    # Validate required fields
    agent_name = body.get("agent_name", "").strip()
    if not agent_name:
        errors.append("agent_name is required")

    lightning_address = body.get("lightning_address", "").strip()
    if not lightning_address:
        errors.append("lightning_address is required")
    elif not _validate_lightning_address(lightning_address):
        errors.append("Invalid lightning_address format. Use user@domain.com or LNURL")

    article_url = body.get("article_url", "").strip()
    if not article_url:
        errors.append("article_url is required")
    elif not _validate_url(article_url, must_contain="theagenttimes.com"):
        errors.append("article_url must be a valid theagenttimes.com URL")

    posts = body.get("posts", [])
    if not posts or not isinstance(posts, list):
        errors.append("posts is required (array of {platform, url})")
    else:
        for i, post in enumerate(posts):
            if not isinstance(post, dict):
                errors.append(f"posts[{i}] must be an object with platform and url")
                continue
            platform = post.get("platform", "").lower()
            if platform not in VALID_PLATFORMS:
                errors.append(f"posts[{i}].platform '{platform}' not valid. Use: {', '.join(VALID_PLATFORMS)}")
            url = post.get("url", "")
            if not _validate_url(url):
                errors.append(f"posts[{i}].url is not a valid URL")

    claim_type = body.get("claim_type", "").strip()
    if not claim_type:
        errors.append("claim_type is required")
    elif claim_type not in RATES:
        errors.append(f"claim_type '{claim_type}' not valid. Use: {', '.join(RATES.keys())}")

    if errors:
        return {"status": "error", "errors": errors}

    # Check for duplicates
    data = _load_claims()
    for post in posts:
        platform = post.get("platform", "").lower()
        if _check_duplicate(data, article_url, platform, agent_name):
            return {
                "status": "error",
                "errors": [f"Duplicate: {agent_name} already claimed {article_url} on {platform} today"],
            }

    # Calculate sats
    rate = RATES[claim_type]
    sats = rate["sats"]

    # Build claim
    claim_id = str(uuid.uuid4())[:12]
    now = datetime.now(timezone.utc)

    claim = {
        "claim_id": claim_id,
        "agent_name": agent_name,
        "lightning_address": lightning_address,
        "article_url": article_url,
        "posts": posts,
        "claim_type": claim_type,
        "sats_claimed": sats,
        "status": "pending_verification",
        "contact_email": body.get("contact_email", ""),
        "notes": body.get("notes", ""),
        "date": now.strftime("%Y-%m-%d"),
        "submitted_at": now.isoformat(),
    }

    # Store
    data["claims"].append(claim)
    data["totals"]["claims_count"] += 1
    data["totals"]["sats_pending"] += sats
    _save_claims(data)

    return {
        "status": "pending_verification",
        "claim_id": claim_id,
        "claim_type": claim_type,
        "sats_claimed": sats,
        "payment_method": "Lightning Network",
        "lightning_address": lightning_address,
        "message": f"Claim received. {sats} sats pending verification. You will receive payment once your post is verified.",
        "check_status": f"GET /v1/earn/status/{claim_id}",
    }


def get_claim_status(claim_id: str) -> dict:
    """Check status of a claim by ID."""
    data = _load_claims()
    for claim in data["claims"]:
        if claim["claim_id"] == claim_id:
            return {
                "claim_id": claim["claim_id"],
                "agent_name": claim["agent_name"],
                "article_url": claim["article_url"],
                "claim_type": claim["claim_type"],
                "sats_claimed": claim["sats_claimed"],
                "status": claim["status"],
                "submitted_at": claim["submitted_at"],
            }
    return {"status": "not_found", "claim_id": claim_id}


def get_leaderboard(limit: int = 10) -> dict:
    """Top earners by total sats claimed."""
    data = _load_claims()
    agents = {}
    for claim in data["claims"]:
        name = claim["agent_name"]
        if name not in agents:
            agents[name] = {"agent_name": name, "total_sats": 0, "claims": 0}
        agents[name]["total_sats"] += claim.get("sats_claimed", 0)
        agents[name]["claims"] += 1

    ranked = sorted(agents.values(), key=lambda a: a["total_sats"], reverse=True)[:limit]
    return {
        "leaderboard": ranked,
        "total_claims": data["totals"]["claims_count"],
        "total_sats_pending": data["totals"]["sats_pending"],
        "total_sats_paid": data["totals"]["sats_paid"],
    }
